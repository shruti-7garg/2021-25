# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VNzSa_ait_EwdTiaIfc9QILtUefiRWSU
"""

from google.colab import files
uploaded = files.upload()

from PIL import Image
import io

uploaded.keys()

uploaded_file = list(uploaded.keys())[0]

image = Image.open(io.BytesIO(uploaded[uploaded_file]))

gray_image = image.convert('L')

gray_image.show()

import matplotlib.pyplot as plt

# Display the image inline
plt.imshow(gray_image, cmap='gray')
plt.axis('off')  # Hide axes
plt.show()

gray_image.save('processed_ecg_image.png')

import numpy as np
from PIL import Image
from torchvision import transforms
import torch

normalized_image = np.array(gray_image) / 255.0

resized_image = gray_image.resize((224, 224))

transform = transforms.Compose([
    transforms.RandomRotation(10),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor()
])

augmented_image = transform(resized_image)

image_array = np.array(resized_image).flatten()

def extract_patches(image_array, patch_size):
    patches = []
    for i in range(0, image_array.shape[0] - patch_size + 1, patch_size):
        for j in range(0, image_array.shape[1] - patch_size + 1, patch_size):
            patches.append(image_array[i:i+patch_size, j:j+patch_size])
    return np.array(patches)

patches = extract_patches(np.array(resized_image), patch_size=16)

tensor_data = torch.tensor(patches, dtype=torch.float32)

attention_mask = torch.ones(tensor_data.shape[0])

image_array = np.array(resized_image)

tensor_data = torch.tensor(image_array, dtype=torch.float32).unsqueeze(0)

rgb_image = gray_image.convert('RGB')


transform = transforms.ToTensor()
tensor_data = transform(rgb_image)

tensor_data = tensor_data.unsqueeze(0)

tensor_data /= 255.0

from transformers import AutoFeatureExtractor, AutoModel

# Load a feature extractor and model for image classification
feature_extractor = AutoFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')
model = AutoModel.from_pretrained('google/vit-base-patch16-224-in21k')

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
tensor_data = tensor_data.to(device)

desired_width = 224
desired_height = 224
resized_image = rgb_image.resize((desired_width, desired_height))

transform = transforms.ToTensor()
tensor_data = transform(resized_image)

tensor_data = tensor_data.unsqueeze(0)

tensor_data /= 255.0

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
tensor_data = tensor_data.to(device)

from transformers import AutoFeatureExtractor, AutoModel

# Load model
feature_extractor = AutoFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')
model = AutoModel.from_pretrained('google/vit-base-patch16-224-in21k')
model.to(device)

model.eval()
with torch.no_grad():
    outputs = model(pixel_values=tensor_data)

print(type(outputs))
print(outputs)

pooler_output = outputs.pooler_output

import torch.nn as nn

class ClassificationHead(nn.Module):
    def __init__(self, hidden_size, num_classes):
        super(ClassificationHead, self).__init__()
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        return self.fc(x)

hidden_size = pooler_output.size(-1)
num_classes = 2

classification_head = ClassificationHead(hidden_size, num_classes)
logits = classification_head(pooler_output)

import torch.nn.functional as F

probabilities = F.softmax(logits, dim=-1)

predicted_class = torch.argmax(probabilities, dim=-1).item()

# Map to class labels
class_labels = ['Healthy', 'Disease']
predicted_label = class_labels[predicted_class]

print(f'Prediction: {predicted_label} (Probability: {probabilities.max().item():.2f})')

#  image and prediction
plt.imshow(resized_image)
plt.title(f'Prediction: {predicted_label} (Probability: {probabilities.max().item():.2f})')
plt.axis('off')
plt.show()

print(type(outputs))
print(outputs)